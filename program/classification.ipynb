{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "maxsize = 10000\n",
    "out_dir = \"../dataset\"\n",
    "save_file = out_dir + \"/dataset.pickle\" # 保存先\n",
    "\n",
    "\n",
    "result = []\n",
    "fs = glob.glob(out_dir+\"/*\")\n",
    "for i,labeldir in enumerate(fs):\n",
    "    print(\"i=\",i)\n",
    "    print(\"labeldir=\",labeldir)\n",
    "    fs0 = glob.glob(labeldir+\"/*\")\n",
    "    for j,f in enumerate(fs0):\n",
    "        if j>=maxsize:break\n",
    "        result.append([i,cv2.imread(f)])\n",
    "\n",
    "pickle.dump(result, open(save_file, \"wb\"))\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "num_classes = 7\n",
    "im_rows = 80\n",
    "im_cols = 60\n",
    "im_color = 3\n",
    "in_shape = (im_rows, im_cols, im_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file =  \"../dataset/dataset.pickle\"\n",
    "data = pickle.load(open(data_file,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for d in data:\n",
    "    (label,img)=d\n",
    "\n",
    "    y.append(label)\n",
    "    X.append(img)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataとtest dataに分類\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8, test_size=0.2,shuffle=True)\n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "#One-Hot形式前のy_testを保存\n",
    "y_test_org = y_test\n",
    "\n",
    "# ラベルデータをOne-Hot形式に変換\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import RandomRotation, RandomZoom\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                    input_shape=in_shape))\n",
    "\n",
    "    #水増し処理を追加\n",
    "    # model.add(RandomTranslation(0.1, 0.1))\n",
    "    model.add(RandomRotation(0.2))\n",
    "    model.add(RandomZoom(0.3))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, y_train,\n",
    "    batch_size=128, epochs=30,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model):\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print('正解率=', score[1], 'loss=', score[0])\n",
    "\n",
    "    pred = model.predict(X_test) # modelは学習させたもの\n",
    "    correct_count = [0] * num_classes\n",
    "    count = [0] * num_classes\n",
    "\n",
    "    for i in range(pred.shape[0]):\n",
    "        prediction = np.argmax(pred[i]) # モデルの予測ラベル取得\n",
    "        answer = y_test_org[i]\n",
    "        count[answer] += 1\n",
    "        if prediction == answer:\n",
    "            correct_count[answer] += 1 # 正解数カウント\n",
    "\n",
    "    accuracy = [correct/N for correct, N in zip(correct_count, count)] # 精度算出\n",
    "\n",
    "    for label, acc in enumerate(accuracy):\n",
    "        print('accuracy for label {} : {}'.format(label, acc))\n",
    "    plt.plot(hist.history['accuracy'])\n",
    "    plt.plot(hist.history['val_accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, mean_absolute_error\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "all_loss=[]\n",
    "all_val_loss=[]\n",
    "all_acc=[]\n",
    "all_val_acc=[]\n",
    "ep=20\n",
    "\n",
    "for train_index, val_index in kf.split(X_train,y_train):\n",
    "\n",
    "    train_data=X_train[train_index]\n",
    "    train_label=y_train[train_index]\n",
    "    val_data=X_train[val_index]\n",
    "    val_label=y_train[val_index]\n",
    "\n",
    "    model=build_model()\n",
    "    history=model.fit(train_data,\n",
    "                      train_label,\n",
    "                      epochs=ep,\n",
    "                      batch_size=128,\n",
    "                      verbose = 1,\n",
    "                      validation_data=(val_data,val_label))\n",
    "\n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "    acc=history.history['accuracy']\n",
    "    val_acc=history.history['val_accuracy']\n",
    "\n",
    "    all_loss.append(loss)\n",
    "    all_val_loss.append(val_loss)\n",
    "    all_acc.append(acc)\n",
    "    all_val_acc.append(val_acc)\n",
    "\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "ave_all_loss=[\n",
    "    np.mean([x[i] for x in all_loss]) for i in range(ep)]\n",
    "ave_all_val_loss=[\n",
    "    np.mean([x[i] for x in all_val_loss]) for i in range(ep)]\n",
    "ave_all_acc=[\n",
    "    np.mean([x[i] for x in all_acc]) for i in range(ep)]\n",
    "ave_all_val_acc=[\n",
    "    np.mean([x[i] for x in all_val_acc]) for i in range(ep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "pred = model.predict(X_test)\n",
    "y_pred = np.mean(pred, axis=0)\n",
    "print(y_pred)\n",
    "print(f'Test Score MAE: {mean_absolute_error(pred, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(model.predict(X_test), axis=1)\n",
    "plt.figure(figsize=(30,15))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "sns.heatmap(cm,  annot=True, fmt='d')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "645002f91107cd0a4a3c1edaaec9aae20745b4a9aa82cf82de3d60e2932c3c3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
